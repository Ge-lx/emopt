import numpy as np
import math
import torch

__author__ = "Sean Hooten"
__copyright__ = 'Copyright 2023 Hewlett Packard Enterprise Development LP.'
__license__ = "BSD-3"
__maintainer__ = "Sean Hooten"
__status__ = "development"

NONZERO = 1e-16
SQRT2 = np.sqrt(2.0)
ISQRT2 = np.sqrt(2.0)/2.0

##############################################################
# Nonlinear Function Definitions, sigma_k(x)
##############################################################
nl_sig = lambda k, x: torch.sigmoid(k*x)
nl_tanh = lambda k, x: 0.5 * (1.0 + torch.tanh(k*x))
nl_erf = lambda k, x: 0.5 * (1.0 + torch.erf(k*x))
nl_line = lambda k, x: torch.clamp(k*x + 0.5, min=0.0, max=1.0)

def nl_sin(k, x):
    kx = k*x
    retval = torch.where(kx > np.pi/2.0,
                         1.0,
                         torch.where(kx < -np.pi/2.0,
                                     0.0,
                                     0.5*(torch.sin(kx)+1.0)
                                     )
                        )
    return retval

def nl_quad(k, x):
    kx = k*x
    retval = torch.where(kx < -ISQRT2,
                         0.0,
                         torch.where(kx < 0,
                                    (ISQRT2 + kx)**2,
                                     torch.where(kx > ISQRT2,
                                                 1.0,
                                                 1.0 - (ISQRT2 - kx)**2),
                                    )
                        )
    return retval

##############################################################
# Differentiable logic operations
##############################################################

def union(list_shapes):
    # this is the main differentiable union function
    return torch.clamp(sum(list_shapes), max=1.0)

def union_b(list_shapes):
    # another option, not as optimally behaved, requires recursion
    if len(list_shapes) == 1:
        return list_shapes[0]
    else:
        ub = union_b(list_shapes[:-1])
        return list_shapes[-1] + ub - list_shapes[-1] * ub

def union_c(k, list_shapes, nl=nl_sig):
    # legacy union
    return nl(k, sum(list_shapes) - 0.5)

def intersection(list_shapes):
    # this is the main differentiable union function
    N = len(list_shapes)
    return torch.clamp(sum(list_shapes), min=N-1, max=N) - (N-1)

def intersection_b(list_shapes):
    # another option
    return math.prod(list_shapes)

def intersection_c(k, list_shapes, nl=nl_sig):
    # legacy intersection
    return nl(k, sum(list_shapes) - (N - 0.5))

##############################################################
# AutoDiff-Compatible Shape Definitions (AutoDiffGeo)
##############################################################

# note below that x and y are simple 1d tensors,
# can be generated by torch.linspace (no torch.meshgrid is required)

def step1d(k, x, v, reverse=False, nl=nl_sig):
    # v = coordinate of transition
    if reverse:
        return nl(k, v-x)
    else:
        return nl(k, x-v)

def rect1d(k, x, v, nl=nl_sig):
    # v[0] = xmin
    # v[1] = xmax
    return nl(k, x-v[0]) * nl(k, v[1]-x)

def rect2d(k, x, y, v, nl=nl_sig):
    # Note: all 2d functions return tensor with shape (len(y), len(x))
    # v[0] = xmin
    # v[1] = xmax
    # v[2] = ymin
    # v[3] = ymax
    return rect1d(k, x, v[:2], nl=nl).view(1,-1) * rect1d(k, y, v[2:], nl=nl).view(-1,1)

def step2d(k, x, y, v, nl=nl_sig):
    # Note: all 2d functions return tensor with shape (len(y), len(x))
    # v[0] = nx (normal in x direction)
    # v[1] = ny (normal in y direction)
    # v[2] = x0, x coordinate of line defining transition
    # v[3] = y0, y coordinate of line defining transition
    vn = v[:2]/v[:2].norm(dim=-1, keepdim=True)
    shape = nl(k, (vn[0]*(x-v[2])).view(1,-1) + (vn[1]*(y-v[3])).view(-1,1))
    return shape

def rect3d(k, x, y, z, v, nl=nl_sig):
    # Note: all 3d functions return tensor with shape (len(z), len(y), len(x))
    # v[0] = xmin
    # v[1] = xmax
    # v[2] = ymin
    # v[3] = ymax
    # v[4] = zmin
    # v[5] = zmax
    return rect1d(k, x, v[:2], nl=nl).view(1,1,-1) * rect1d(k, y, v[2:4], nl=nl).view(1,-1,1) * rect1d(k, z, v[4:], nl=nl).view(-1,1,1)

def rectnd(k, list_coords, v, nl=nl_sig):
    # v[i,0] = min in i'th coordinate
    # v[i,1] = max in i'th coordinate
    n = len(list_coords)
    view = n*[1]
    shape = torch.as_tensor([1.0]).view(view)
    for count, r in enumerate(list_coords):
        view[count] = -1
        shape = shape * rect1d(k, r, v[count,:], nl=nl).view(view)
        view[count] = 1
    return shape

def depth(shape, k, z, v, nl=nl_sig):
    # convenience function that extends 2d shape of shape (len(y), len(x)) to 3d planar shape in the z dimension
    # Note: all 3d functions return tensor with shape (len(z), len(y), len(x))
    # v[0] = zmin
    # v[1] = zmax
    assert len(shape.shape) == 2
    return rect1d(k, z, v, nl=nl).view(-1,1,1) * shape.unsqueeze(0)

def poly2d(k, x, y, v, nl=nl_sig):
    # v[i,0] = x coordinate of i'th vertex
    # v[i,1] = y coordinate of i'th vertex
    # vertices must be oriented clockwise
    # only supports convex polygons
    dxs = torch.diff(v, append=v[0:1,:], dim=0)
    cents = 0.5*dxs + v
    nvec = torch.cat([dxs[:,1:2], -dxs[:,0:1]], dim=1)
    nvec = nvec/nvec.norm(dim=-1, keepdim=True)
    return nl(k, nvec[:,0] * (x.view(1,-1,1) - cents[:,0]) + nvec[:,1] * (y.view(-1,1,1) - cents[:,1])).prod(-1)

def circ2d(k, x, y, v, nl=nl_sig):
    # v[0] = radius
    # v[1] = x coordinate of center
    # v[2] = y coordinate of center
    R = torch.sqrt(NONZERO + ((x-v[1])**2).view(1,-1) + ((y-v[2])**2).view(-1,1))
    return nl(k, v[0] - R)

def polar2d(k, x, y, v, theta0=0., ord=4, nl=nl_sig):
    # v[0] = radius
    # v[1] = perturbation to radius (defined along theta)
    # v[2] = x coordinate of center
    # v[3] = y coordinate of center
    # theta0 = nominal rotation (this can be a differentiable parameter if desired)
    # ord = cosine order cos(ord*theta)
    theta = theta0 + torch.arctan2((x-v[2]).view(1,-1), (y-v[3]).view(-1,1))
    R = torch.sqrt(NONZERO + ((x-v[2])**2).view(1,-1) + ((y-v[3])**2).view(-1,1))
    return nl(k, v[0] * (1.0 + v[1] * torch.cos(ord*theta)) - R)

if __name__=='__main__':
    pass
